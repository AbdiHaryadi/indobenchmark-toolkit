{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "from transformers import BartModel, BartForConditionalGeneration, GPT2LMHeadModel\n",
    "from indobenchmark import IndoNLGTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartModel were not initialized from the model checkpoint at indobenchmark/indobart and are newly initialized: ['shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "bart_model = BartModel.from_pretrained('indobenchmark/indobart')\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('indobenchmark/indogpt')\n",
    "tokenizer = IndoNLGTokenizer.from_pretrained('indobenchmark/indobart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aku adalah anak pertama dari tiga bersaudara. aku lahir di kota kecil yang sama dengan ayahku.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_input = torch.LongTensor([tokenizer.encode('<s> aku adalah anak', add_special_tokens=False)])\n",
    "gpt_out = gpt_model.generate(gpt_input)\n",
    "tokenizer.decode(gpt_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aku suka sekali makan di sini. aku suka sekali dengan menu yang ada di sini. aku'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_input = torch.LongTensor([tokenizer.encode('<s> aku suka sekali makan', add_special_tokens=False)])\n",
    "gpt_out = gpt_model.generate(gpt_input)\n",
    "tokenizer.decode(gpt_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hai, bagaimana kabar kalian? semoga sehat selalu ya. kali ini saya akan membahas tentang cara membuat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_input = torch.LongTensor([tokenizer.encode('<s> hai, bagaimana kabar', add_special_tokens=False)])\n",
    "gpt_out = gpt_model.generate(gpt_input)\n",
    "tokenizer.decode(gpt_out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mï¿½ paraek\\x1f'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_input = tokenizer.prepare_input_for_generation(['aku adalah <mask>'], model_type='indobart', return_tensors='pt')\n",
    "bart_out = bart_model(**bart_input)\n",
    "tokenizer.decode(bart_out.last_hidden_state.topk(1).indices[:,:,:].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[ para para para\\x1f[', 'para para para para\\x1fn')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_input = tokenizer.prepare_input_for_generation(['dia adalah anak <mask>','<mask> adalah anak gembala'], \n",
    "    decoder_inputs=['dia adalah anak <mask>','aku adalah anak <mask>'], model_type='indobart', return_tensors='pt')\n",
    "bart_out = bart_model(**bart_input)\n",
    "tokenizer.decode(bart_out.last_hidden_state.topk(1).indices[0,:,:].squeeze()), tokenizer.decode(bart_out.last_hidden_state.topk(1).indices[1,:,:].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (indobenchmark)",
   "language": "python",
   "name": "env_indobenchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
